{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:49.781128Z",
     "start_time": "2024-08-23T06:18:49.760560Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "torch.cuda.current_device()\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "# 路径\n",
    "TRAIN_PATH = '../data/ccks_2019_train_split.csv'\n",
    "TEST_PATH = '../data/ccks_2019_test_split.csv'\n",
    "MODEL_PATH1 = '../model/'\n",
    "MODEL_PATH2 = '../model/'\n",
    "MODEL_PATH_MAC = '../model/'\n",
    "MODEL_LOCAL_PATH = '../RoBERTa_zh_L12_PyTorch'\n",
    "\n",
    "# 超参数\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 50\n",
    "\n",
    "# 预设\n",
    "# 设备\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# tag2index\n",
    "tag2index = {'O': 0,\n",
    " 'B-解剖部位': 1,\n",
    " 'I-解剖部位': 2,\n",
    " 'B-手术': 3,\n",
    " 'I-手术': 4,\n",
    " 'B-疾病和诊断': 5,\n",
    " 'I-疾病和诊断': 6,\n",
    " 'B-影像检查': 7,\n",
    " 'I-影像检查': 8,\n",
    " 'B-药物': 9,\n",
    " 'I-药物': 10,\n",
    " 'B-实验室检验': 11,\n",
    " 'I-实验室检验': 12}\n",
    "index2tag = {v: k for k, v in tag2index.items()}\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "# 预处理\n",
    "def data_preprocessing(dataset, is_train):\n",
    "    # 数据str转化为list\n",
    "    dataset['text_split'] = dataset['text'].apply(list)\n",
    "    # token\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_LOCAL_PATH)\n",
    "    texts = dataset['text_split'].array.tolist()\n",
    "    token_texts = []\n",
    "    for text in tqdm(texts):\n",
    "        tokenized = tokenizer.encode_plus(text=text,\n",
    "                                          max_length=MAX_LEN,\n",
    "                                          return_token_type_ids=True,\n",
    "                                          return_attention_mask=True,\n",
    "                                          return_tensors='pt',\n",
    "                                          padding='max_length',\n",
    "                                          truncation=True)\n",
    "        token_texts.append(tokenized)\n",
    "\n",
    "    # 训练集有tag，测试集没有tag\n",
    "    tags = None\n",
    "    if is_train:\n",
    "        dataset['tag'] = dataset['BIO_anno'].apply(lambda x: x.split(sep=' '))\n",
    "        tags = []\n",
    "        for tag in tqdm(dataset['tag'].array.tolist()):\n",
    "            index_list = [0] + [tag2index[t] for t in tag] + [0]\n",
    "            if len(index_list) < MAX_LEN:  # 填充\n",
    "                pad_length = MAX_LEN - len(index_list)\n",
    "                index_list += [tag2index['O']] * pad_length\n",
    "            if len(index_list) > MAX_LEN:  # 裁剪\n",
    "                index_list = index_list[:MAX_LEN-1] + [0]\n",
    "            tags.append(index_list)\n",
    "        tags = torch.LongTensor(tags)\n",
    "\n",
    "    return token_texts, tags\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:50.421392Z",
     "start_time": "2024-08-23T06:18:50.412416Z"
    }
   },
   "id": "c4522a7e089abd42",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Bert_BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, tag2index):\n",
    "        super(Bert_BiLSTM_CRF, self).__init__()\n",
    "        self.tagset_size = len(tag2index)\n",
    "\n",
    "        # bert层\n",
    "        self.bert = BertModel.from_pretrained(MODEL_LOCAL_PATH)\n",
    "        # config = self.bert.config\n",
    "        # lstm层\n",
    "        self.lstm = nn.LSTM(input_size=768, hidden_size=128, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        # dropout层\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        # Dense层\n",
    "        self.dense = nn.Linear(in_features=256, out_features=self.tagset_size)\n",
    "        # CRF层\n",
    "        self.crf = CRF(num_tags=self.tagset_size)\n",
    "\n",
    "        # 隐藏层\n",
    "        self.hidden = None\n",
    "\n",
    "    # 负对数似然损失函数\n",
    "    def neg_log_likelihood(self, emissions, tags=None, mask=None, reduction=None):\n",
    "        return -1 * self.crf(emissions=emissions, tags=tags, mask=mask, reduction=reduction)\n",
    "\n",
    "    def forward(self, token_texts, tags):\n",
    "        \"\"\"\n",
    "        token_texts:{\"input_size\": tensor,  [batch, 1, seq_len]->[batch, seq_len]\n",
    "                    \"token_type_ids\": tensor,  [batch, 1, seq_len]->[batch, seq_len]\n",
    "                     \"attention_mask\": tensor  [batch, 1, seq_len]->[batch, seq_len]->[seq_len, batch]\n",
    "                     }\n",
    "        tags:  [batch, seq_len]->[seq_len, batch]\n",
    "        bert_out:  [batch, seq_len, hidden_size(768)]->[seq_len, batch, hidden_size]\n",
    "        self.hidden:  [num_layers * num_directions, hidden_size(128)]\n",
    "        out:  [seq_len, batch, hidden_size * 2(256)]\n",
    "        lstm_feats:  [seq_len, batch, tagset_size]\n",
    "        loss:  tensor\n",
    "        predictions:  [batch, num]\n",
    "        \"\"\"\n",
    "        texts, token_type_ids, masks = token_texts['input_ids'], token_texts['token_type_ids'], token_texts['attention_mask']\n",
    "        texts = texts.squeeze(1)\n",
    "        token_type_ids = token_type_ids.squeeze(1)\n",
    "        masks = masks.squeeze(1)\n",
    "        bert_out = self.bert(input_ids=texts, attention_mask=masks, token_type_ids=token_type_ids)[0]\n",
    "        bert_out = bert_out.permute(1, 0, 2)\n",
    "        # 检测设备\n",
    "        device = bert_out.device\n",
    "        # 初始化隐藏层参数\n",
    "        self.hidden = (torch.randn(2, bert_out.size(0), 128).to(device),\n",
    "                       torch.randn(2, bert_out.size(0), 128).to(device))\n",
    "        out, self.hidden = self.lstm(bert_out, self.hidden)\n",
    "        lstm_feats = self.dense(out)\n",
    "\n",
    "        # 格式转换\n",
    "        masks = masks.permute(1, 0)\n",
    "        masks = masks.clone().detach().bool()\n",
    "        # masks = torch.tensor(masks, dtype=torch.uint8)\n",
    "        # 计算损失值和预测值\n",
    "        if tags is not None:\n",
    "            tags = tags.permute(1, 0)\n",
    "            loss = self.neg_log_likelihood(lstm_feats, tags, masks, 'mean')\n",
    "            predictions = self.crf.decode(emissions=lstm_feats, mask=masks)  # [batch, 任意数]\n",
    "            return loss, predictions\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions=lstm_feats, mask=masks)\n",
    "            return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:50.861281Z",
     "start_time": "2024-08-23T06:18:50.846321Z"
    }
   },
   "id": "14c2742ce1626da1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": [
    "class NerDataset(Dataset):\n",
    "    def __init__(self, token_texts, tags):\n",
    "        super(NerDataset, self).__init__()\n",
    "        self.token_texts = token_texts\n",
    "        self.tags = tags\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"token_texts\": self.token_texts[index],\n",
    "            \"tags\": self.tags[index] if self.tags is not None else None,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_texts)\n",
    "\n",
    "\n",
    "class NerDatasetTest(Dataset):\n",
    "    def __init__(self, token_texts):\n",
    "        super(NerDatasetTest, self).__init__()\n",
    "        self.token_texts = token_texts\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"token_texts\": self.token_texts[index],\n",
    "            \"tags\": 0\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:51.301717Z",
     "start_time": "2024-08-23T06:18:51.286757Z"
    }
   },
   "id": "7d8cd595fd5565ea",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torchcrf import CRF\n",
    "from transformers import BertModel\n",
    "\n",
    "\n",
    "class Bert_CRF(nn.Module):\n",
    "    def __init__(self, tag2index):\n",
    "        super(Bert_CRF, self).__init__()\n",
    "        self.tagset_size = len(tag2index)\n",
    "\n",
    "        # bert层\n",
    "        self.bert = BertModel.from_pretrained(MODEL_LOCAL_PATH)\n",
    "        # dense层\n",
    "        self.dense = nn.Linear(in_features=768, out_features=self.tagset_size)\n",
    "        # CRF层\n",
    "        self.crf = CRF(num_tags=self.tagset_size)\n",
    "\n",
    "        # 隐藏层\n",
    "        self.hidden = None\n",
    "\n",
    "    def neg_log_likelihood(self, emissions, tags=None, mask=None, reduction=None):\n",
    "        return -1 * self.crf(emissions=emissions, tags=tags, mask=mask, reduction=reduction)\n",
    "\n",
    "    def forward(self, token_texts, tags):\n",
    "        \"\"\"\n",
    "        token_texts:{\"input_size\": tensor,  [batch, 1, seq_len]->[batch, seq_len]\n",
    "                    \"token_type_ids\": tensor,  [batch, 1, seq_len]->[batch, seq_len]\n",
    "                     \"attention_mask\": tensor  [batch, 1, seq_len]->[batch, seq_len]->[seq_len, batch]\n",
    "                     }\n",
    "        tags:  [batch, seq_len]->[seq_len, batch]\n",
    "        bert_out:  [batch, seq_len, hidden_size(768)]->[seq_len, batch, hidden_size]\n",
    "        feats:  [seq_len, batch, tagset_size]\n",
    "        loss:  tensor\n",
    "        predictions:  [batch, num]\n",
    "        \"\"\"\n",
    "        texts, token_type_ids, masks = token_texts.values()\n",
    "        texts = texts.squeeze(1)\n",
    "        token_type_ids = token_type_ids.squeeze(1)\n",
    "        masks = masks.squeeze(1)\n",
    "        bert_out = self.bert(input_ids=texts, attention_mask=masks, token_type_ids=token_type_ids)[0]\n",
    "        bert_out = bert_out.permute(1, 0, 2)\n",
    "        feats = self.dense(bert_out)\n",
    "\n",
    "        # 格式转换\n",
    "        masks = masks.permute(1, 0)\n",
    "        masks = masks.clone().detach().bool()\n",
    "        # 计算损失之和预测值\n",
    "        if tags is not None:\n",
    "            tags = tags.permute(1, 0)\n",
    "            loss = self.neg_log_likelihood(feats, tags, masks, 'mean')\n",
    "            predictions = self.crf.decode(emissions=feats, mask=masks)\n",
    "            return loss, predictions\n",
    "        else:\n",
    "            predictions = self.crf.decode(emissions=feats, mask=masks)\n",
    "            return predictions\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:51.687505Z",
     "start_time": "2024-08-23T06:18:51.674539Z"
    }
   },
   "id": "7ae5a50551b06903",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import precision_score, recall_score\n",
    "\n",
    "# 计算f1值\n",
    "def get_f1_score(tags, predictions):\n",
    "    tags = tags.to('cpu').data.numpy().tolist()\n",
    "    temp_tags = []\n",
    "    final_tags = []\n",
    "\n",
    "    int_tags = []\n",
    "    f_int_tags = []\n",
    "    predictions_int = []\n",
    "    for index in range(len(predictions)):\n",
    "        # predictions先去掉头，再去掉尾\n",
    "        predictions[index].pop()\n",
    "        length = len(predictions[index])\n",
    "        temp_tags.append(tags[index][1:length])\n",
    "        int_tags.append(tags[index][1:length])\n",
    "\n",
    "        predictions[index].pop(0)\n",
    "        predictions_int = predictions.copy()\n",
    "        # 格式转化，转化为List(str)\n",
    "        temp_tags[index] = [index2tag[x] for x in temp_tags[index]]\n",
    "        predictions[index] = [index2tag[x] for x in predictions[index]]\n",
    "\n",
    "        final_tags.append(temp_tags[index])\n",
    "        f_int_tags.append(int_tags[index])\n",
    "\n",
    "\n",
    "    f1 = f1_score(final_tags, predictions, average='micro')\n",
    "    precision = 0\n",
    "    predcision = precision_score(final_tags, predictions)\n",
    "    recall =  recall_score(final_tags, predictions)\n",
    "\n",
    "    return {\n",
    "        'recall': recall,\n",
    "        'predcision': predcision,\n",
    "        'micro_f1': f1,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:52.172281Z",
     "start_time": "2024-08-23T06:18:52.154329Z"
    }
   },
   "id": "fe6206cea9bdbc83",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "# 训练\n",
    "def train(train_dataloader, model, optimizer, epoch):\n",
    "    for i, batch_data in enumerate(train_dataloader):\n",
    "        token_texts = batch_data['token_texts'].to(DEVICE)\n",
    "        tags = batch_data['tags'].to(DEVICE)\n",
    "        loss, predictions = model(token_texts, tags)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            f1_obj = get_f1_score(tags, predictions)\n",
    "            micro_f1 = f1_obj['micro_f1']\n",
    "            predcision = f1_obj['predcision']\n",
    "            recall = f1_obj['recall']\n",
    "            print(f'Epoch:{epoch} | i:{i} | loss:{loss.item()} | Micro_F1:{micro_f1} | predcision: {predcision} | recall: {recall}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:18:52.898496Z",
     "start_time": "2024-08-23T06:18:52.879547Z"
    }
   },
   "id": "6e495d1a7ab4c19a",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = pd.read_csv(TRAIN_PATH, encoding='utf8')\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-22T19:27:31.828250Z",
     "start_time": "2024-08-22T19:27:31.528238Z"
    }
   },
   "id": "f4626d8c7c2ebf45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "0              0  ，患者2008年9月3日因“腹胀，发现腹部包块”在我院腹科行手术探查，术中见盆腹腔肿物，与肠...   \n",
       "1              1  于2015-7-6行剖腹探查+膀胱旁肿物切除+骶前肿物切除+肠表面肿物切除术，术程顺利，，术...   \n",
       "2              2  ，患者于2011年9月29日在我院因“子宫内膜癌II期”在全麻上行“广泛全子宫切除+两侧附件...   \n",
       "3              3  术程顺利，，术后病理回报：腹水未见癌；（全子宫+两附件）送检子宫大小为10*6*4CM，宫腔...   \n",
       "4              4  于2011年10月11日、11月16日行TP（泰素+伯尔定）方案化疗2程，化疗后出现轻度恶心...   \n",
       "...          ...                                                ...   \n",
       "2695        2738  ，患者1月前体检发现直肠肿物，，外院肠镜提示：直肠距肛门5-9CM肿物，，活检病理：腺癌，完...   \n",
       "2696        2739  腹泻 1度，皮肤反应1度，恶心0度，乏力1度，泌尿系0度，骨髓抑制0度,2016-6-2继续...   \n",
       "2697        2740  ，患者2012-05-25前因“便血3月余”入院，经肠镜及病理检查确诊乙状结肠腺癌。外院影像...   \n",
       "2698        2741  2013年3月13日、2013年4月02日、2013年4月23日、2013年5月16日、20...   \n",
       "2699        2742  2013-12-31，我院MDT会诊：结合患者外院CT，评估患者肿瘤进展PD，建议患者行XE...   \n",
       "\n",
       "                                               BIO_anno  \n",
       "0     O O O O O O O O O O O O O O B-解剖部位 O O O O B-解...  \n",
       "1     O O O O O O O O O O B-手术 I-手术 I-手术 I-手术 I-手术 I...  \n",
       "2     O O O O O O O O O O O O O O O O O O O B-疾病和诊断 ...  \n",
       "3     O O O O O O O O O O O O O B-解剖部位 O O O O O O B...  \n",
       "4     O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "...                                                 ...  \n",
       "2695  O O O O O O O O O O B-解剖部位 I-解剖部位 O O O O O O ...  \n",
       "2696  B-解剖部位 O O O O O O O O O O O O O O O O O O O O...  \n",
       "2697  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "2698  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "2699  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "\n",
       "[2700 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>BIO_anno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>，患者2008年9月3日因“腹胀，发现腹部包块”在我院腹科行手术探查，术中见盆腹腔肿物，与肠...</td>\n",
       "      <td>O O O O O O O O O O O O O O B-解剖部位 O O O O B-解...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>于2015-7-6行剖腹探查+膀胱旁肿物切除+骶前肿物切除+肠表面肿物切除术，术程顺利，，术...</td>\n",
       "      <td>O O O O O O O O O O B-手术 I-手术 I-手术 I-手术 I-手术 I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>，患者于2011年9月29日在我院因“子宫内膜癌II期”在全麻上行“广泛全子宫切除+两侧附件...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O B-疾病和诊断 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>术程顺利，，术后病理回报：腹水未见癌；（全子宫+两附件）送检子宫大小为10*6*4CM，宫腔...</td>\n",
       "      <td>O O O O O O O O O O O O O B-解剖部位 O O O O O O B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>于2011年10月11日、11月16日行TP（泰素+伯尔定）方案化疗2程，化疗后出现轻度恶心...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>2738</td>\n",
       "      <td>，患者1月前体检发现直肠肿物，，外院肠镜提示：直肠距肛门5-9CM肿物，，活检病理：腺癌，完...</td>\n",
       "      <td>O O O O O O O O O O B-解剖部位 I-解剖部位 O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>2739</td>\n",
       "      <td>腹泻 1度，皮肤反应1度，恶心0度，乏力1度，泌尿系0度，骨髓抑制0度,2016-6-2继续...</td>\n",
       "      <td>B-解剖部位 O O O O O O O O O O O O O O O O O O O O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>2740</td>\n",
       "      <td>，患者2012-05-25前因“便血3月余”入院，经肠镜及病理检查确诊乙状结肠腺癌。外院影像...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>2741</td>\n",
       "      <td>2013年3月13日、2013年4月02日、2013年4月23日、2013年5月16日、20...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>2742</td>\n",
       "      <td>2013-12-31，我院MDT会诊：结合患者外院CT，评估患者肿瘤进展PD，建议患者行XE...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28933/28933 [00:13<00:00, 2216.88it/s]\n",
      "100%|██████████| 28933/28933 [00:00<00:00, 39340.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        5, 6, 6, 6, 6, 0, 0, 7, 8, 0, 0, 0, 5, 6, 6, 0, 1, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n        1, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(TRAIN_PATH, encoding='utf8')\n",
    "# 数据预处理\n",
    "token_texts, tags = data_preprocessing(train_dataset, is_train=True)\n",
    "# 数据集装载\n",
    "\n",
    "tags[20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T09:01:15.869185300Z",
     "start_time": "2023-12-16T09:00:59.906958500Z"
    }
   },
   "id": "dfea626f12a1c37f"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 3389,  860, 8038,  100, 8038,  124,  127,  119,  126,  360,  510,\n          100, 8038,  128,  129, 3613,  120, 1146,  510,  100, 8038,  122,  129,\n         3613,  120, 1146,  510,  100,  100,  122,  124,  121,  120,  129,  121,\n          100,  155,  155,  100,  149, 8024,  860, 1798,  974, 4607, 8024, 4868,\n         2562, 3926, 3504, 8024, 6427, 6241, 3837, 1164, 8024, 6134, 2658, 5632,\n         4197, 8024, 3635, 1057, 4567, 2147, 8024, 5632, 1220,  860,  855, 8024,\n         3389,  860, 1394,  868,  511, 2552, 5511, 5592, 7346, 2595, 8024, 5592,\n         2398, 1788, 8024, 5498, 5569, 5490,  678, 3313, 1350, 8024, 1059, 5592,\n         3313, 6239, 1350, 2460, 2382, 1259, 1779, 8024, 3187, 1327, 4578, 1353,\n         6663, 4578, 1350, 5491, 5165, 2476,  511, 5592, 1371, 4919, 1220, 2595,\n         3843, 7509, 7346, 2595, 8039, 5499, 7885, 7509, 3633, 2382, 8024, 3313,\n         7319, 1350, 7770, 6444, 5499, 7885, 7509, 1350, 3698, 6814, 3717, 1898,\n          511, 5550, 3393, 4495, 4415, 2482, 3289, 3633, 2382, 8024, 3187,  904,\n         2482, 1350, 1400, 4960, 4535, 2501, 8024, 1392, 3491,  860, 3475, 4960,\n         3187, 1327, 4578, 1350, 1371, 1140, 4578,  511, 5550, 5490, 6235, 3187,\n         7384, 6629, 8024, 1352, 5513, 1277, 1371, 1140, 4578, 7346, 2595,  511,\n         5497, 7305, 1912, 4495, 3658, 3187, 4535, 2501,  511, 1724, 5501, 3187,\n         4535, 2501, 8024, 1392, 1068, 5688, 3833, 1220, 3633, 2382, 8039, 5491,\n         1213, 5491, 2476, 1213, 3633, 2382, 8039, 5508,  753,  510,  676, 5491,\n         5588, 1353, 2198, 8024, 6656, 5607, 5588, 1353, 2198, 3633, 2382, 2100,\n         1762, 8024, 2349, 3694, 5023, 4567, 4415, 1353, 2198, 2519, 3313, 2471,\n         1139,  511, 1381,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_texts[20]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T12:14:45.499601500Z",
     "start_time": "2023-11-07T12:14:45.457789700Z"
    }
   },
   "id": "ce10f52a714c7912"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 256])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_texts[20]['attention_mask'].shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T12:14:46.171002Z",
     "start_time": "2023-11-07T12:14:46.163022700Z"
    }
   },
   "id": "5442773a5a09e3aa"
  },
  {
   "cell_type": "code",
   "source": [
    "def execute():\n",
    "    # 加载训练集\n",
    "    train_dataset = pd.read_csv(TRAIN_PATH, encoding='utf8')\n",
    "\n",
    "    # 数据预处理\n",
    "    token_texts, tags = data_preprocessing(train_dataset, is_train=True)\n",
    "    # 数据集装载\n",
    "    train_dataset = NerDataset(token_texts, tags)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    # 构建模型\n",
    "    model = Bert_BiLSTM_CRF(tag2index=tag2index).to(DEVICE)\n",
    "    #model = Bert_CRF(tag2index=tag2index).to(DEVICE)\n",
    "    # 初始化模型参数优化器\n",
    "\n",
    "    crf_params = list(map(id, model.crf.parameters()))\n",
    "\n",
    "    base_params = filter(lambda p: id(p) not in crf_params,\n",
    "                     model.parameters())\n",
    "\n",
    "    optimizer_params = [\n",
    "          {'params': base_params},\n",
    "          {'params': model.crf.parameters(), 'lr': 2e-5 * 100},\n",
    "    ]\n",
    "\n",
    "    optimizer = optim.AdamW(optimizer_params, lr=2e-5)\n",
    "    print(f\"GPU_NAME:{torch.cuda.get_device_name()} | Memory_Allocated:{torch.cuda.memory_allocated()}\")\n",
    "    # 模型训练\n",
    "    for i in range(EPOCH):\n",
    "        print(f\"{i} Epoch\")\n",
    "        train(train_dataloader, model, optimizer, i)\n",
    "        # 保存模型\n",
    "        torch.save(model.state_dict(), MODEL_PATH2 + str(i) + '.pkl')\n",
    "        test_result = test(MODEL_PATH2 + str(i) + '.pkl', EPOCH)\n",
    "        #print(test_result)\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), MODEL_PATH_MAC + 'final.pkl')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:19:01.494301Z",
     "start_time": "2024-08-23T06:19:01.472256Z"
    }
   },
   "id": "c4249518bfbb53af",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "#测试集预测实体标签\n",
    "def test(model_path, model_id):\n",
    "    # 加载数据集\n",
    "    test_dataset = pd.read_csv(TEST_PATH, encoding='utf8')\n",
    "    #测试集的tags_list\n",
    "    test_tags_true = test_dataset['BIO_anno'].apply(lambda x: x.split(sep=' '))\n",
    "    test_tags_true = test_tags_true.array.tolist()\n",
    "    # 数据预处理\n",
    "    token_texts, _ = data_preprocessing(test_dataset, is_train=False)\n",
    "    # 装载测试集\n",
    "    dataset_test = NerDatasetTest(token_texts)\n",
    "    test_dataloader = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    # 构建模型\n",
    "    model = Bert_BiLSTM_CRF(tag2index).to(DEVICE)\n",
    "    #model = Bert_CRF(tag2index).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    # 模型预测\n",
    "    model.eval()\n",
    "    predictions_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch_data in enumerate(test_dataloader):\n",
    "            token_texts = batch_data['token_texts'].to(DEVICE)\n",
    "            predictions = model(token_texts, None)\n",
    "            predictions_list.extend(predictions)\n",
    "\n",
    "    # 将预测结果转换为文本格式\n",
    "    entity_tag_list = []\n",
    "    result = []\n",
    "    index2tag = {v: k for k, v in tag2index.items()}  # 反转字典\n",
    "    for i, (text, predictions) in enumerate(zip(test_dataset['text'], predictions_list)):\n",
    "        # 删除首位和最后一位\n",
    "        predictions.pop()\n",
    "        predictions.pop(0)\n",
    "        text_entity_tag = []\n",
    "        result_tag = []\n",
    "        for c, t in zip(text, predictions):\n",
    "            if t != 0:\n",
    "                text_entity_tag.append(c + index2tag[t])\n",
    "                result_tag.append(index2tag[t])\n",
    "            else:\n",
    "                result_tag.append('O')\n",
    "        result.append(result_tag)\n",
    "        entity_tag_list.append(\" \".join(text_entity_tag))  # 合并为str并加入列表中\n",
    "\n",
    "    result_df = pd.DataFrame(data=entity_tag_list, columns=['result'])\n",
    "    result_df.to_csv('../result.csv')\n",
    "\n",
    "    for t in range(len(test_tags_true)):\n",
    "      if len(test_tags_true[t]) != len(result[t]):\n",
    "        test_tags_true[t] = test_tags_true[t][0: len(result[t])]\n",
    "\n",
    "    predcision = precision_score(test_tags_true, result)\n",
    "    recall =  recall_score(test_tags_true, result)\n",
    "    class_report = classification_report(test_tags_true, result, digits=6)\n",
    "\n",
    "    print(f\"{model_id} test f1_score = \" + str(f1_score(test_tags_true, result)))\n",
    "    print(f\"{model_id} test predcision_score = \" + str(predcision))\n",
    "    print(f\"{model_id} test recall_score = \" + str(recall))\n",
    "    print(f\"{model_id} test report = \" + class_report)\n",
    "    \n",
    "    return {\n",
    "        \"f1\": f1_score(test_tags_true, result),\n",
    "        \"pred\": predcision,\n",
    "        'recall': recall,\n",
    "        'report': class_report,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-23T06:19:07.205985Z",
     "start_time": "2024-08-23T06:19:07.183987Z"
    }
   },
   "id": "4696eade610d72c7",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "execute()",
   "id": "5453bcdc716442c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
